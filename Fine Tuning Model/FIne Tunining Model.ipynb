{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "YnkSERO0yuLc",
   "metadata": {
    "id": "YnkSERO0yuLc"
   },
   "source": [
    "**1. Created own dataset for text classification. It should contain at least 2000 words in total and at least three categories with at least 100 examples per category (an example can be a poem or a paragraph from a book).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da8837f-27ff-4c8e-9394-911a454431d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2da8837f-27ff-4c8e-9394-911a454431d3",
    "outputId": "469cf288-6088-43b0-ccaa-eb256e3d65fa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"literature\",\n          \"tech\",\n          \"quote\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \" All limitations are self-imposed. Break your barriers and expand your horizons.\",\n          \" In the stillness of the night, the ancient castle's halls whispered with echoes of past conversations.\",\n          \" A new AI system now can learn from minimal data, revolutionizing machine learning efficiency and application.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-24b27441-e28f-47f4-ac01-17bf102fce9a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>literature</td>\n",
       "      <td>Waves crashed against the shore in roaring ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tech</td>\n",
       "      <td>A startup introduced a revolutionary battery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quote</td>\n",
       "      <td>Aspire to inspire before we expire, make a ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quote</td>\n",
       "      <td>Die with memories, not dreams. Live life to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>literature</td>\n",
       "      <td>What we think, we become. Our thoughts shape ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24b27441-e28f-47f4-ac01-17bf102fce9a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-24b27441-e28f-47f4-ac01-17bf102fce9a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-24b27441-e28f-47f4-ac01-17bf102fce9a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-343559e7-30ce-41db-8007-5ad85b6fdb60\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-343559e7-30ce-41db-8007-5ad85b6fdb60')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-343559e7-30ce-41db-8007-5ad85b6fdb60 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "     Category                                               Text\n",
       "0  literature   Waves crashed against the shore in roaring ap...\n",
       "1        tech   A startup introduced a revolutionary battery ...\n",
       "2       quote   Aspire to inspire before we expire, make a ma...\n",
       "3       quote   Die with memories, not dreams. Live life to i...\n",
       "4  literature   What we think, we become. Our thoughts shape ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = '/content/Labeled_Unique_Text_Classification_Dataset.txt'\n",
    "data = pd.read_csv(file_path, delimiter=':', header=None, names=['Category', 'Text'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q-laDipcyq1l",
   "metadata": {
    "id": "Q-laDipcyq1l"
   },
   "source": [
    "**2. Split the dataset into training (at least 240examples) and test (at least 60 examples) sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "VDsRZ6BsyQyH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDsRZ6BsyQyH",
    "outputId": "d5e2d856-93f2-4c44-b75d-3569052dd473"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 2), (60, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Category'] = data['Category'].str.strip()\n",
    "data['Text'] = data['Text'].str.strip()\n",
    "\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "split_index = int(0.8 * len(data))\n",
    "train_data = data[:split_index]\n",
    "test_data = data[split_index:]\n",
    "\n",
    "(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6RUVT2d_yQX9",
   "metadata": {
    "id": "6RUVT2d_yQX9"
   },
   "source": [
    "**3. Fine-tune a pre-trained language model capable of generating text (e.g., GPT) that you can take, e.g., from the Hugging Face Transformers library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35d02f-d80c-4774-892f-d07e16efe448",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fe05a34c26b2428383572f806cb02bfa",
      "04c159956c8d4ee6a08d4650e955c018",
      "bdf6636da8474f4785b5933b24652322",
      "a6f0656d58684e4c8e2660ebe1fc48ec",
      "e1461513dd80429da88ba2ec093b98ca",
      "7e6864d88e554cd196fefdfcef38b267",
      "2d67a9356a7e49d9b4bfe81cf83dce30",
      "3f61ea24bc5341ab88b4a2cb3eba9942",
      "44bdf11275fe4266bb6407408243c692",
      "272002f3fe8e4c818db56fbea39b23d7",
      "07ab09512dee4611bc210b5e5725be9f",
      "977229de041c499393460ddce5181fa8",
      "2c1e11d21cce4a0e9994f5b8d519e7d9",
      "b4cfa900e8ab4cf395b96399dba41553",
      "7910112fd7584cc0a4b9d2a66918428d",
      "5f2e02d0007246429278a814e07471e8",
      "c8b2c4ee3b2f445da94da3e98b726ea0",
      "ea871b111ac94ad3a2d02e7463c430ae",
      "3064172fad024b1c8ca96ec28364bbb0",
      "99d109eaf77b42a69463ec4d13a47691",
      "ad331e4810ed4c34836599f8adf99e6b",
      "795de3f73e2141ed8daca377401af6a5",
      "11e0cdeff6934fa9a1b9ca28b7635bcd",
      "26697172aac94628b6399786f2a7adeb",
      "80e890e4dcf1496ba4294ddc98b01f68",
      "d01f8f4debeb41d08e0a8c725f897d99",
      "5dbfd44b4e15434081f48d208d733f7a",
      "3ced840b3d594f30a4d886f0f615746b",
      "d055c9d2cba040a2a35c0a3fed1411a4",
      "d313e59d5f0c494fb442f4410e524c48",
      "d4cea58ad19b45888cc5b990f6ab0f8b",
      "bdf8eef8bc944cb8975b090e5d56a11d",
      "6b59c743947a42cf864daa9cfcd18db3",
      "8d000289f4914306b77b9193d28d96b1",
      "4e983189cd7549ce8f10043a4a484a0c",
      "352dc76925834fa3b148de10a4fc7ca6",
      "133c67fff47148aebe03411bee7ada59",
      "78306aef74ce40d19b06b0c43c5f17b9",
      "90732fd7181343ac9ae4223e03761890",
      "40ed871c9fe04f639bafe99e372930bf",
      "fcedbe57d45b4644b850876b722c7274",
      "0a95edb1f15a4e80a72138be633484ae",
      "91077b0654c647c2aa3fe850a00a7c03",
      "93aa168d10ce47968a6f158df0d26ef7",
      "e95c31c8d5d54843b76e798687d39e7d",
      "8881f04446ae4fd983bcd19c8b3b3fd2",
      "67dd3e0fa84a48489d6db044bd28ae04",
      "2c0d44eb5984444484ccb91fb6d66970",
      "bebb43de62ac4700b63939c5b45dee2f",
      "f09fa1d274224bd89ced4b38c289d073",
      "47588e959b1449d29e312a462471d3d2",
      "9de9d390cc9c45c1a418d528a8e3d527",
      "c17d1659cb514b349b87fb92aabaab00",
      "994d034669c14f048d8a6aaf48cecf2e",
      "820f03c4457f4f938232217d19413e19",
      "49eb0db92558489aa60a94794aeec2f4",
      "6ca2fb7441334d1c94f0ffe5fc817b65",
      "81340b81ee35472a9f249111ffa96019",
      "851e9ce310b7441a93fe9eb4c1e5eb4a",
      "745776a83ea842a59c8bda8f86fa4f2f",
      "1931344d3ab549bf902229d317a6b2dc",
      "b3855be3fed349d7b956500b7b86ccc5",
      "9c99aecfc4244bf1b66b3a1d5aa1057b",
      "14fc2933ff2f4e008e0d460fd4b1325f",
      "71221350ad54455ca7cde3855f2397c5",
      "b6e92b64bc6f41b3a7c5973007f6c54d",
      "79f289ebce1f439489ac06cb4b976eb6",
      "2378e95299b5467c8649158b49460d4f",
      "9ca80d450f3c4ea38c64de89a02b04d9",
      "4e662e96f91d455bad8ebebc7a82b2cf",
      "52fee9b2d4614da7a1afb61610c0269d",
      "0c20909480f94cfaa0dc7c2898b2b52e",
      "d575fc54bafd4097b7454806b50880a4",
      "372612504783488daae75f540dc85b34",
      "8e9f09046bad4681bb19d817828353a0",
      "ff31b3d80d1a4642bfb2871b93ed86ab",
      "0d6b59b4b96a476a9f0c90e90f753f9f",
      "d92d8d59b4fa4a96a69291143eb5a553",
      "fb3190b56b4e431f8ed2d16317a3438b",
      "5b2df574bec9408399a27f4836af06fa",
      "2240cccb5092454d8306806c43ca382e",
      "5fc998a889ad446a955ddd96b1c7140f",
      "c87adc692b0d405f88e316caf896e7ad",
      "6ff5da7cc37f405f8335a1a994b700b8",
      "c575757f48324f11ac624d65e9a04d8c",
      "b86c116bf9d240b583c8c830d359b043",
      "83afb872e6f74af2b39064fe05bb572d",
      "aa9ff223b5424ca5b1d6543c84241d3b"
     ]
    },
    "id": "fb35d02f-d80c-4774-892f-d07e16efe448",
    "outputId": "4d5620ef-d081-47ad-abec-fac809684a89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
      "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe05a34c26b2428383572f806cb02bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977229de041c499393460ddce5181fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e0cdeff6934fa9a1b9ca28b7635bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d000289f4914306b77b9193d28d96b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95c31c8d5d54843b76e798687d39e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49eb0db92558489aa60a94794aeec2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f289ebce1f439489ac06cb4b976eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92d8d59b4fa4a96a69291143eb5a553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7c0a9636c8b0> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function infer_framework at 0x7c0a9636c8b0> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "30/30 [==============================] - 88s 688ms/step - loss: 1.4431 - accuracy: 0.7756 - val_loss: 0.1639 - val_accuracy: 0.9689\n",
      "Epoch 2/3\n",
      "30/30 [==============================] - 12s 414ms/step - loss: 0.0901 - accuracy: 0.9807 - val_loss: 0.0417 - val_accuracy: 0.9949\n",
      "Epoch 3/3\n",
      "30/30 [==============================] - 13s 423ms/step - loss: 0.0373 - accuracy: 0.9939 - val_loss: 0.0346 - val_accuracy: 0.9949\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.0346 - accuracy: 0.9949\n",
      "Eval Loss: 0.03460855782032013, Eval Accuracy: 0.994921863079071\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "import tensorflow as tf\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, TFAutoModelForCausalLM\n",
    "import pandas as pd\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Text'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "def map_model_input(input_ids, attention_mask, labels):\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}, labels\n",
    "\n",
    "train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_dataset['input_ids'], train_dataset['attention_mask'], train_dataset['input_ids']))\n",
    "train_tf_dataset = train_tf_dataset.map(map_model_input).shuffle(1000).batch(8)\n",
    "test_tf_dataset = tf.data.Dataset.from_tensor_slices((test_dataset['input_ids'], test_dataset['attention_mask'], test_dataset['input_ids']))\n",
    "test_tf_dataset = test_tf_dataset.map(map_model_input).batch(16)\n",
    "\n",
    "model = TFAutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss,metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_tf_dataset, epochs=3, validation_data=test_tf_dataset)\n",
    "\n",
    "eval_loss, eval_acc = model.evaluate(test_tf_dataset)\n",
    "print(f\"Eval Loss: {eval_loss}, Eval Accuracy: {eval_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8uS430Oyxcl",
   "metadata": {
    "id": "d8uS430Oyxcl"
   },
   "source": [
    "\n",
    "1. **Model Architecture and Training Setup**:\n",
    "   - The model used is TFAutoModelForCausalLM, which is a TensorFlow implementation of the GPT-2 model for language modeling tasks.\n",
    "   - The optimizer used is Adam with a learning rate of 5e-5.\n",
    "   - The loss function used is SparseCategoricalCrossentropy, and the model is compiled with the 'accuracy' metric.\n",
    "\n",
    "2. **Training**:\n",
    "   - The model is trained for 3 epochs on the training dataset (`train_tf_dataset`).\n",
    "   - During training, both loss and accuracy metrics are logged for both the training and validation datasets (`test_tf_dataset`).\n",
    "   - As the epochs progress, both training and validation losses decrease, and accuracy increases, indicating that the model is learning and improving its performance.\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - After training, the model is evaluated on the test dataset (`test_tf_dataset`).\n",
    "   - The evaluation metrics show that the model achieves a low evaluation loss of 0.0346 and a high evaluation accuracy of 99.49%.\n",
    "\n",
    "4. **Analysis**:\n",
    "   - The model's high evaluation accuracy suggests that it generalizes well to unseen data.\n",
    "   - The training and validation loss/accuracy curves indicate that the model is not overfitting, as there is no significant gap between the training and validation metrics. Both training and validation loss decrease consistently across epochs, and the validation accuracy reaches a high level comparable to the training accuracy.\n",
    "\n",
    "5. **Conclusion**:\n",
    "   - Based on the provided content, there is no evidence of overfitting. The model demonstrates strong performance on both the training and test datasets, with high accuracy and low loss values.\n",
    "   - The provided code effectively trains and evaluates a GPT-2 model for a language modeling task, showcasing its ability to generate text sequences with high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WIynGaD9z1gr",
   "metadata": {
    "id": "WIynGaD9z1gr"
   },
   "source": [
    "To improve accuracy, consider the following steps:\n",
    "\n",
    "Fine-Tuning: Fine-tune the GPT-2 model on a downstream task related to your specific domain. This involves training the model on a task-specific dataset to adapt it to your use case.\n",
    "\n",
    "Hyperparameter Tuning: Experiment with different hyperparameters, such as learning rate, batch size, and model architecture, to find the combination that works best for your data.\n",
    "\n",
    "Data Augmentation: Increase the diversity of your training data through data augmentation techniques, such as adding noise, paraphrasing, or using different sentence structures.\n",
    "\n",
    "More Training Data: If possible, obtain more labeled data for training. A larger and more diverse dataset can often lead to better model performance.\n",
    "\n",
    "Model Architecture: Experiment with different model architectures or try more advanced models that might be better suited for your task.\n",
    "\n",
    "Regularization: Apply regularization techniques, such as dropout, to prevent overfitting on the training data.\n",
    "\n",
    "Error Analysis: Analyze the mistakes made by the model on the test set. Identify patterns in misclassifications and consider incorporating this knowledge into the training process.\n",
    "\n",
    "Good dataset : if possible proper collection of images in data without any distortion,blur, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57089b0e-774b-4b5e-a5c4-68d261836d3e",
   "metadata": {
    "id": "57089b0e-774b-4b5e-a5c4-68d261836d3e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
